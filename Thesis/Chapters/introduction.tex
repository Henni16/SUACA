
\section{Motivation}

Knowing your machine is a major advantage when trying to optimize high-performance scientific code. \iaca\ \cite{iaca} is a tool by Intel to analyze \emph{X86} machine code with respect to a specific microarchitecture. However, it has some drawbacks that often times prevent it from being useful in practice. The main reason is that it doesn't support the newest processors. \iaca\ $3.0$, which was released in late 2017, supports the \nth{4} (Haswell) to the \nth{6} (Skylake) generation of Intel core microarchitectures. Skylake was released in 2015. \iaca\ $2.3$ additionally supports the \nth{2} (Sandy Bridge) and the \nth{3} (Ivy Bridge) generation. So at the time of writing \iaca\ is about three years behind and further development remains unclear.\\
The second complication is that \iaca\ is closed source. Its user guide \cite{userguide} is the only documentation it has which provides little to no information about how it actually computes its output. As a result a user will often find himself wondering how its output fits the analyzed program.\\
In this work we present \suaca\ (Saarland University Architecture Code Analyzer), an open source alternative. It uses measurements provided by \cite{Andreas} which are parsed during runtime. This way a user does not rely on a software update of the tool as he can simply perform the measurements on his own, should we not already support his microarchitecture. Note that this is only possible with Intel architectures so far. At the time of writing \suaca\ supports all Intel core microarchitectures from the \nth{1} (Nehalem) to the \nth{8} (Coffee Lake) generation, except for the server variant of Skylake.
\newpage

\section{Intel's microarchitectures}



In order to understand some of our computations one also needs some basic knowledge about Intel's microarchitectures. They use the \emph{X86} instruction
\input{Chapters/Pipeline}

set. However, they don't execute those instructions directly. They will translate them into a sequence of so called \microops, which can then be executed. Unfortunately, there is little to no official documentation about those \microops, neither about the functionality of an individual one nor about their interaction with each other. From the measurements we can conclude that each microarchitecture has its own \microops\ which makes it even harder to find reliable information.\\ \autoref{fig:Pipeline} shows a sketch of a microarchitecture by Intel. We can see the front end including the decoder unit which is responsible for the translation of the instructions into the \microops. In our simulation we will only consider the number of \microops\ the front end produces each cycle, which is currently $4$--$6$ depending on the architecture. Our main interest lies in the execution engine or more precisely in the scheduler (or reservation station) and the ports. The scheduler is responsible for the distribution of the \microops\ over the ports. As mentioned before, a certain amount of those will be loaded into it by the frond end in each cycle. It has a maximum capacity, which also depends on the specific architecture (the scheduler of the Sandy Bridge architecture we will be using for most of our examples has a capacity of $54$). The most important property we can observe from this figure are the ports. Each port can be seen as a pipeline that a \microop\ can run through in order to be executed. On the ports themselves lie the actual execution units of the processor like the \emph{ALU}, \emph{MULTIPLEXER} and so on. Every port can hold a single \microop\ per cycle and they support pipelining. So they will be free again in the next cycle. The only exception from this is the \emph{DIVIDER} unit which is slow at executing and can be blocked for multiple cycles. Usually it is not necessary that the \microops\ are executed in program order. The so called out-of-order execution is possible whenever there is no dependency between the respective \emph{X86} instructions or the \microops\ themselves.
 
 %\begin{wrapfigure}[25]{l}{0.6\textwidth}
 %   \includegraphics[width=0.6\textwidth]{Intel_Nehalem_arch}
 %  \caption{Intel Nehalem architecture \cite{nehalem}}
 % \label{fig:NHMfull}
 %\end{wrapfigure}
 
 
 %\begin{wrapfigure}[15]{r}{0.6\textwidth}
 %  \includegraphics[clip, trim=0.5cm 2cm 9.78cm 20cm,width=0.6\textwidth]{Intel_Nehalem_arch}
 %\caption{Detailed view \cite{nehalem}}
 %\label{fig:NHMdetail}
 %\end{wrapfigure}
 
\section{\iaca's analysis} 

In order to use \iaca\ one first has to prepare the code with the two markers that are defined in the \emph{iacaMarks.h} header. As \iaca\ is mostly used to analyze innermost loops of scientific code we will show how those markers are inserted there:

\begin{mdframed}[backgroundcolor=light-gray, roundcorner=10pt,leftmargin=1, rightmargin=1, innerleftmargin=15, innertopmargin=1,innerbottommargin=1, outerlinewidth=1, linecolor=light-gray]
    \begin{lstlisting}
    #include "iacaMarks.h"
    
    int main(void) {
    
        while (condition) {
        (*@\textcolor{Green}{IACA\_START}  @*)
        //Some code here
        }
        (*@\textcolor{Green}{IACA\_END}  @*)
    
        return 0;
    }
    \end{lstlisting}
\end{mdframed}

When writing assembly code one can simply insert the markers that are defined in the \emph{iacaMarks.h} header manually.\\
In the following we will perform an analysis with \iaca. The analyzed program is not of particular interest here, but we will further discuss it later. At the moment we want to explain how \iaca's output should be understood. For this purpose consider the following example:

\begin{example}
Throughput Analysis Report
--------------------------
Block Throughput: 2.86 Cycles       Throughput Bottleneck: FrontEnd

Port Binding In Cycles Per Iteration:
---------------------------------------------------------------------------------------
|  Port  |  0   -  DV  |  1   |  2   -  D   |  3   -  D   |  4   |  5   |  6   |  7   |
---------------------------------------------------------------------------------------
| Cycles | 1.6    0.0  | 1.4  | 0.0    0.0  | 0.0    0.0  | 0.0  | 1.4  | 1.6  | 0.0  |
---------------------------------------------------------------------------------------

N - port number or number of cycles resource conflict caused delay, DV - Divider pipe (on port 0)
D - Data fetch pipe (on ports 2 and 3), CP - on a critical path
F - Macro Fusion with the previous instruction occurred
* - instruction micro-ops not bound to a port
^ - Micro Fusion happened
# - ESP Tracking sync uop was issued
@ - SSE instruction followed an AVX256/AVX512 instruction, dozens of cycles penalty is expected
X - instruction not supported, was not accounted in Analysis

| Num Of |                    Ports pressure in cycles                     |    |
|  Uops  |  0  - DV  |  1  |  2  -  D  |  3  -  D  |  4  |  5  |  6  |  7  |    |
---------------------------------------------------------------------------------
|   1    | 0.1       | 0.3 |           |           |     | 0.3 | 0.3 |     |    | mov rax, 0x1
|   1    | 0.9       |     |           |           |     |     | 0.1 |     |    | cmp rcx, 0x0
|   0F   |           |     |           |           |     |     |     |     |    | jnz 0x7
|   1    |           | 0.3 |           |           |     | 0.5 | 0.2 |     | CP | add rbx, rax
|   1    | 0.6       |     |           |           |     |     | 0.3 |     |    | jmp 0x5
|   1    |           | 0.4 |           |           |     | 0.3 | 0.3 |     | CP | add rbx, rax
|   1    |           | 0.3 |           |           |     | 0.3 | 0.4 |     | CP | add rbx, rbx
Total Num Of Uops: 6
\end{example}

First we can see that \iaca\ computed a \emph{block throughput} of $2.86$ cycles which is the average number of cycles needed to execute the program ($\frac{Total\ number\ of\ cycles}{Number\ of\ iterations}$) and is therefore the value a programmer should try to optimize.\\
The analysis also shows the front end and the average port bindings. The port bindings represent the sum of the port pressure values we see in the bottom table.\\
A port is pressured whenever a \microop\ is assigned to it. Due to port pipelining the pressure values equal the number of \microops\ that were assigned to the port and will therefore add up to the number of \microops\ (apart from rounding errors). The divider pipe is an exception to this, but we will explain this in \autoref{sec:dividerpipe}.
 
 
\section{Scope of work}

Like mentioned before we will present a tool that is able to analyze \emph{X86} assembler code with respect to a specific microarchitecture. Just like \iaca\ our tool is able to find byte markers inside a compiled file and analyze the code in between.  We are using Intel's \emph{X86 Encoder Decoder} library \cite{xed} to disassemble said file, which allows us to support files of the \emph{ELF}, \emph{PECOFF} and \emph{MACHO} format.\\

After disassembling \suaca\ will perform a dependency analysis on the instructions and parse the measurement file. Finally it will perform a simulation of the code. It won't consider the actual effect of the instructions, only their latencies, dependencies and port usage. The output will be very similar to \iaca' and additionally \suaca\ offers some supplementary options which can be used to further investigate the given program. During all analyses the instructions are first considered in program order, although instruction reordering is still possible as we will see in \autoref{sec:chooseport}. For several reasons, which we will discuss in the following, our simulation will compute an estimate of the code's performance, not total numbers.\\
We will discuss all available options of \suaca\ in \autoref{chap:functionality}. In \autoref{chap:algorithms} we will then explain in detail how the most important parts of the simulation and the dependency analyzes are implemented.



\section{Measurements}
\label{sec:measurements}

As mentioned before a crucial part of \suaca's functionality are the measurements provided by \cite{Andreas}. Consider this snippet from the XML-measurement-file file:


\begin{lstlisting}[language=XML, basicstyle=\ttfamily\scriptsize, breaklines=false]
<instruction ... iform="ADD_LOCK_MEMv_GPRv" ...>
    <operand idx="2" type="reg" ...>RAX,RCX,RDX,RBX,...</operand>
    <operand idx="3" type="flag" ...>OF</operand>
    <operand idx="4" type="flag" ...>SF</operand>
    ...
    <architecture name="NHM">
        <measurement port15="2" port2="1" port3="1" port4="1" total_uops="5">
            <latency cycles="19" ... targetOp="3"/>
            <latency cycles="19" ... targetOp="4">
            ...
        <\measurement>
    </architecture>
<\instruction>
\end{lstlisting}

We dotted out some unnecessary or redundant information. As we can see in the first line this is the information for the instruction with the \emph{iform} ``ADD\_LOCK\_MEMv\_GPR''. \emph{iform} is an enum from the XED Library (\cite{xed}) that is used to identify instructions. We can extract the following information from our snippet:

\begin{itemize}
    \item One of the \emph{RAX, RCX, RDX, \dots} registers is an operand and they have the id $2$. We only need the mapping of $id \rightarrow register$ here as the xed library will tell us which operands are actually used in the analyzed programs. Similarly the flags also have their ids. The flags are the single bits of the \emph{RFLAGS} register in \emph{X86}.
    \item We have some measurements for the Intel Nehalem microarchitecture.
    \item When simulating Nehalem the instruction consists of $5$ \microops. Two of which can use ports $1$ and $5$ and one each can use port $2$, $3$ and $4$.
    \item It will take $19$ cycles to compute the result for the operand with id $3$.
\end{itemize}

Most instructions have several latency items, depending on the number and kind of operands. In our case there is no information for operand $2$ as the instruction won't write to those registers. However, the latency for the operand with id $4$ is also $19$ cycles. Some instructions actually produce their results in a specific order. It might be that one operand is available after $3$ cycles and another one after $5$, so an instruction that only needs the first of those operands has to wait $3$ cycles whereas another one that needs the second operand has to wait $5$. \suaca\ can simulate this behavior as it knows which operand is causing the dependency. When simulating the whole instruction \suaca\ takes the maximum of those values. Note that those values are always best case i.e., no port was blocked and no dependency occurred.\\
We can already observe why the lack of information on the \microops\ pose a major problem. We cannot know how the the above mentioned latency values come about. Probably those early results are computed by some of the \microops, but as we do not know which ones we can not always precisely compute the correct latency should an instruction be delayed. If the \microops\ of an instruction do not depend on each other it is even possible that the order of the results changes, which we also can not simulate.
%TODO last paragraph is questionable

\section{Related work}

Like mentioned before one can find general information about \iaca\ at its website \cite{iaca}. The user's guide \cite{userguide} gives additional information about the usage and provides some examples. \iaca\ is developed by Israel Hirsh and Gideon~S.\\

Andreas Abel \cite{Andreas} provides the measurements which enable us to compute our results.\\

Jan Laukemann \cite{osaca-thesis} implemented an open source alternative to \iaca\ called \osaca\ \cite{osaca-web}. It relies on the measurements provided by Johannes Hofmann \cite{ibench}. We will discuss the difference between the three tools in \autoref{chap:eval}.
