When trying to analyze a program, the user sometimes needs to fully understand how the results were calculated. Especially if he wants use them to improve his code. Therefore we will discuss \suaca's most important algorithms in this chapter.

\section{Dependency analysis}
\label{sec:depanalysis}

\subsection{Single iteration}

Here we want to take a look at the algorithm that computes the dependency graph. \\
First we want to discuss a simpler version that ignores the control flow of the program.

\begin{algorithm}[H]
    \SetAlgoLined
    \caption{Dependency analysis without control flow}
    \label{alg:depsingle}
    \SetKwInOut{Input}{Input}
    \SetKwInOut{Output}{Output}
    \Input{Instructionlist InstList}
    \Output{Dependencygraph DG}
    Map $:=$ map from Register to line\;
    DG $:=$ Graph that has the same nodes as CFG, but no edges\;
    \ForEach{Instruction $i$ in InstList} {
         \ForEach{Register-Operand $r$ in Operands($i$)} {
             \eIf{IsRead($r$)} {
                 DG.addEdge(Map[$r$], LineOf($i$))\;
             }{
                Map[$r$] = LineOf(i)\;
            }
        }
    }
    \Return DG\;
\end{algorithm}

\newpage

Where
\begin{itemize}
    \item $Operands(i)$ returns a list of all operands of instruction $i$.
    \item $IsRead(r)$ returns true if the operand $r$ will be read and false if it will be written to.
    \item $LineOf(i)$ returns the line of instruction $i$ in the original program.
\end{itemize}

This algorithm will iterate over all instructions ``line after line''. For each instruction $i$ it will then iterate over all of its operands. For each operand we'll check if it is accessed via read or write. If it is read the algorithm will add an edge from the last written access to the current line. If it is written to the algorithm will map the register to the current line.\\

The runtime of this algorithm can be described as $\mathcal{O}(n*m)$ where $n$ is the number of instructions and $m$ the maximum number of operands that occur in the program.\\

Note that we consider every operand as a register. In practice an operand can of course be a memory address. In this case \suaca\ will extract all registers from that address and treat them as a read operand. \suaca\ does not support memory dependencies so far as we would need to keep track of the whole memory. As we have seen in \autoref{fig:wloop} \suaca\ is able to differentiate between the different flags. For readability we ignore the special case of the \emph{RFLAGS} register here.

Now we want to take a look at the control flow sensitive algorithm \suaca\ actually uses. 
\newpage

\begin{algorithm}[H]
    \SetAlgoLined
    \caption{Control flow sensitive dependency analysis}
    \label{alg:dep}
    \SetKwFunction{deps}{Dep-Analysis-Start}
    \SetKwFunction{dep}{Dep-Analysis}
    \SetKwProg{Fn}{Function}{:}{\Return DG\;}
    \Fn{\deps{CFG}}{
        Map $:=$ map from Register to line\;
        DG $:=$ Graph that has the same nodes as CFG, but no edges\;
        Node $:=$ Startnode of CFG\;
        \dep{CFG, DG, Map, Node}\;
    }
    \SetKwProg{Fn}{Function}{:}{}
    \Fn{\dep{CFG, DG, Father-Map, Node}}{
        Map $:=$ copy of Father-Map\;
        \While{HasSuccessor(Node)} {
            \ForEach{Register-Operand $r$ in Operands($i$)} {
                \eIf{IsRead($r$)} {
                    DG.addEdge(Map[$r$], LineOf($i$))\;
                }{
                    Map[$r$] = LineOf(i)\;
                }
            }
            Node $\leftarrow$ Successor(Node, 0)\;
            \If{numSuccessors(Node) $>$ 1} {
                \dep{CFG, DG, Map, Successor(Node, 1)}\; 
            }
        }
    }
\end{algorithm}

Where
\begin{itemize}
    \item $numSuccessors(Node)$ returns the number of successors of $Node$ in its underlying graph.
    \item $Successor(Node, i)$ returns the $i$th successor of $Node$ in the Graph $Node$ belongs to.
    \item $HasSuccessor(Node)$ returns true if $numSuccessors(Node) >= 1$.
\end{itemize}

This time we'll ``climb along'' the $CFG$. If we never face a branch, i.e.\ $numSuccessors()$ never returns a value greater than $1$, this algorithm will do exactly the same as the one we have just seen.\\
In the case of $numSuccessors() > 1$ we'll make another call of $Dep-Analysis$ on the ``right branch''. From there on there will be two analyses, one for every branch in the $CFG$. Each analysis has its own $Map$ as there can be different writes on each branch. Note that we won't join the two analyses as we would need to find the first mutual descendant.\\
In the worst case every instruction is a branch, so we would spawn a new function for every one of them. This leads to a runtime of $\mathcal{O}(n^2*m)$.\\
For this algorithm we assume no backbranches, i.e.\ no loops, inside the program. In practice \suaca\ will simply check for every branch if it is a backbranch and should the situation arise ignore it.


\subsection{Multiple iterations}

When telling \suaca\ to run the program in multiple loops we need to adjust the dependency analysis algorithm as there can arise some ``loop dependencies''. To solve this, we'll simply consider the program twice. So we'll append a copy of the program to itself, compute the $CFG$ and then run the algorithm above. Because we know the original length of our program we can extract all ``loop dependencies'' from the resulting dependency graph.


\section{Simulation of the front end}
\label{sec:simfrontend}

Although our main task is to simulate the reservation station we still want to consider the front end in our analysis. Depending on the micro architecture the front end is able to produce a certain amount of \microops\ every cycle. For example the Sandy Bridge architecture will produce at most $4$ \microops\ per cycle. However, we still have to consider the capacity of the reservation station as the front end might be faster than the execution itself. The reservation station of the Sandy Bridge architecture has a maximum capacity of $54$ \microops.\\
We will now briefly discuss how our simulation actually performs those loads.

\begin{algorithm}[H]
    \SetAlgoLined
    \caption{Load instructions into reservation station}
    List $:=$ List of all instructions\;
    Waiting $:=$ First element of List that is not fully loaded\;
    Loadable $:= max(Loads\ per\ cycle, remaining\ space\ in\ station)$\;
    \While{Loadable $> 0$} {
        loaded $:=$ load\microops(Waiting, Loadable)\;
        Loadable $\leftarrow$ Loadable $-$ loaded\;
        \eIf{fullyLoaded(Waiting)} {
            Waiting $\leftarrow$ List.GetNextElement(Waiting)\;
        } {
            break\;
        }
    }
\end{algorithm}
\newpage
Where
\begin{itemize}
    \item load\microops(Waiting, $x$) loads up to $x$ \microops\ of \emph{Waiting} and returns the number of \microops\ that were actually loaded.
    \item $fullyLoaded(Waiting)$ returns true if all \microops\ of \emph{Waiting} have been loaded into the reservation station.
    \item $List.GetNextElement(Waiting)$ returns the successor element of \emph{Waiting} in List.
\end{itemize}

So it is possible that an instruction is partially (i.e.\ only some of its \microops) loaded into the reservation station.

\section{Choosing the ports}
\label{sec:chooseport}

In this section we are going to discuss how exactly the ports which an instruction uses are chosen. As we've seen in \autoref{lst:xml} we know of how many \microops\ an instruction consists and which ports those \microops\ can use. As seen in \autoref{sec:simfrontend}, an instruction can be loaded partially, which we will have to consider here.\\
The following algorithm contains several crucial details to the simulation. First we will see how \suaca\ tries to distribute all \microops\ equally over all ports. It will also demonstrate the exact situations in which we will execute an instruction. Lastly it will explain how the \textbf{had to wait} and \textbf{caused to wait} columns we introduced in \autoref{sec:plain} are computed. 
\newpage

\begin{algorithm}[H]
    \SetAlgoLined
    \caption{Chose ports for loaded instructions}
    \SetKwInOut{Input}{Input}
    \Input{Instruction $:=$ First element in Instructionqueue}
    \While{loaded\_\microops(Instruction) $> 0$} {
        \eIf{$!all\_fathers\_done(Instruction)$} {
            Instruction.has\_to\_wait++\;
            \ForEach{Father $\in$ Fathers(Instruction)} {
                Father.caused\_to\_wait++\;
                Father.caused\_to\_wait\_depedency(Instruction)++\;
                Instruction.had\_to\_wait\_depedency(Father)++\;
            }
        } {
            Executable $:= true$\;
            \If{!is\_fully\_loaded(Instruction)}{Executable $\leftarrow false$\;}
            \ForEach{\microop\ $\mu$ $\in$ loaded\microops(Instruction)} {
                Success $:=$ assign\_to\_ports($\mu$, Instruction)\;
                \If{!Success} {
                    Executable $\leftarrow false$\;
                }
            }
            \eIf{Executable} {
                add\_to\_executionlist(Instruction)\; \label{line:if}
            }{
                Blamed $:=$ Set of instructions\; \label{line:else}
                \ForEach{p $\in$ blocked\_ports(Instruction)} {
                    \If{!Blamed.contains(p.using\_instruction())} {
                        p.using\_instruction().caused\_to\_wait++\;
                        p.using\_instruction().caused\_to\_wait\_port(p)\;
                        Instruction.had\_to\_wait\_port(p)\;
                        Blamed.add(p.using\_instruction())\;
                    }
                }
                Instruction.has\_to\_wait++\;
            }          
        }
        Instruction $\leftarrow$ Instructionqueue.next(Instruction)\;
    }
\end{algorithm}

~\\[-1em]
\begin{algorithm}[H]
    \label{alg:assign}
    \SetAlgoLined
    \caption{Assign \microop\ to port}
    \SetKwInOut{Input}{Input}
    \Input{\microop\ $\mu$, Instruction $I$}
    Success $\leftarrow true$\;
    \ForEach{p $\in$ PortQueue} {
        \If{$\mu$.can\_use(p) \textbf{and} p.is\_free()} {
            p.uses($\mu$)\;
            \Return $true$\;
        }
    }
    \Return Success\;
\end{algorithm}

So this algorithm iterates over all instructions in program order as long as the current instruction is at least partially loaded. For each instruction it will first check if all of its dependencies have been resolved. If not it can't be executed and the delay counters have to be increased. Notice that we have separate counters for the cumulative delays and the special delays, which are only needed for the detailed analysis (\autoref{sec:detail}). We will see the same behavior for the ports and this explains why the special delays won't always sum up to the cumulative ones.\\
If all dependencies have been resolved \suaca\ will try to assign all \microops\ of the instruction to a port. To achieve this the algorithm will iterate over all \microops\ that have been loaded into the reservation station. Note that this will ignore all \microops\ that have been put into a port already. The function \textbf{\emph{assign\_to\_ports(\microop, Instruction)}} is described in algorithm \ref{alg:assign}. This function will iterate over all ports in prior usage order and assign the \microop\ if possible. More precisely \emph{PortQueue} contains all ports and is sorted by usage throughout the whole simulation. If possible it will assign the \microop\ to the port and return a success. If no usable port was free it will return a fail. If all \microops\ of an instruction are currently in the port pipeline this algorithm will basically just put the instruction into the execution list.\\
We can observe that this is a greedy algorithm that is obviously not optimal in regards to the distribution of all \microops\ over the ports. However, we assume that this greedy algorithm comes close to what the reservation stations are doing in reality.\\
If the assignment or the load of a single \microop\ failed the flag \emph{Executable} will be set to \emph{false}. As we can see in \autoref{line:if} the instruction will only added to the execution list (which we will further discuss in \autoref{sec:execute}) if this flag is set. This means that an instruction is only executed if all of its \microops\ could be assigned to a port. We are doing this, because of our measurements. As we've seen in \autoref{sec:measurements} those will always contain the best case for latency. The biggest problem we face here is the missing information about the \microops. We don't know anything about the dependencies between them and so we don't know if there is an order in which those have to be executed, or if they can be executed simultaneously. So we have to assume a delay as soon as a single \microop\ is denied a port although that might not actually be the case in reality. This means that we will potentially overestimate the latency of a single instruction although it is possible that \suaca\ will actually underestimate the throughput of a program as one can note in the following examples.\\


Consider two instructions \emph{X} and \emph{Y}. \emph{X} consists of two \microops\ one of which can use port $0$ the other can use port $1$. \emph{Y} only consists of one which can use port $1$. \emph{X} is in front of \emph{Y} in program order, both are fully loaded, not dependent on each other and have a latency of $2$ cycles.\\
What \suaca\ ``doesn't know'' is that the the second \microop\ (port $1$) of \emph{X} depends on the first (port $0$). So the simulation will do the following: In the first cycle it will assign \emph{X} to ports $0$ and $1$. There is no port left for \emph{Y} so it won't be added to the execution list. This will happen in the second cycle and as \emph{Y}'s latency was two cycles \suaca\ will compute a throughput of three cycles (as \emph{X} was executed in the first and second).\\
However, in reality \emph{X} won't block port $1$ in the first cycle as this particular \microop\ depends on the one that uses port $0$. So in the first cycle \emph{X} will only use port $0$. \emph{Y} can then freely use port $1$. In the second cycle \emph{X} can then use port $1$. No port was ever blocked so there simply won't be a delay, both instructions could be executed simultaneously. So the ``real throughput'' of our example would be two cycles.\\

Now we will consider the same example but with switched instruction order of \emph{X} and \emph{Y}. In this case \suaca\ will first assign \emph{Y}'s \microop\ to port $1$. It will then try to assign \emph{X}, but it will only be able to assign the first \microop\ to port $0$ as port $1$ is blocked. As discussed before \emph{X} will therefore not be added to the execution list. In the second cycle the leftover of \emph{X} will be assigned to a port and the execution will start. As the latency was two cycles the simulation will stop after the third cycle.\\
Again this is an overestimation of the reality. Due to the dependency of the second \microop\ of \emph{X} it doesn't matter that \emph{Y} blocks port $1$ in the first cycle. \emph{X} only needs port $0$ in the first cycle and in the second cycle it can then freely use port $1$. Again the ``real throughput'' of our example would be two cycles.\\

Finally we will construct an example were our simulation actually underestimates the throughput. We can once more use our two instructions \emph{X} and \emph{Y}. This time we assume that \emph{Y} can't be executed in the first cycle, because of a dependency. Our simulation basically works like in our first case, except for the reason why \emph{Y} can't be executed. So it will compute a throughput of three cycles for those two instructions.\\
In reality \emph{Y} will be denied port $1$ in the second cycle as it will by used by \emph{X}. So the execution will start in the third cycle and end in the fourth.\\

Note that it is still impossible that the latency of a single instruction is underestimated as we will always simulation the execution of at least as many cycles as we measured under a best case scenario. Also an important detail is, that it is impossible for an instruction to block itself. So if multiple \microops\ of a single instruction need to use the same port this will not cause a delay. This is again due to the measurements as the delay caused by ``inner instructional port blockings'' is already included in the best case runtime. We did not include this in the algorithm above for the sake of readability.\\

Ultimately we will consider the rest of the algorithm starting in \autoref{line:else}. This part will increase the counters similar to what we've seen at the start of the algorithm. Notable here is the function \textbf{\emph{blocked\_ports(Instruction)}} that will return all ports that have been blocked during the assignment phase.



\section{Executing applicable instructions}
\label{sec:execute}

\begin{algorithm}[H]
    \SetAlgoLined
    \caption{Execute applicable instructions}
    \ForEach{I $\in$ Executionlist} {
        I.executed\_cycles$++$\;
        \If{I.executed\_cycles $=$ I.latency} {
            Instructionqueue.remove(I)\;
        }
        inform\_children\_im\_done(I)\;
    }
    Executionlist.clear()\;
\end{algorithm}

This part is rather simple. Every instruction knows its latency and how many cycles it has been executed. This value gets increased and if the latency is hit it will be removed from the Instructionqueue. The most interesting part here is the function \textbf{\emph{inform\_children\_im\_done(Instruction)}}. As we've seen in \autoref{sec:measurements} the children of an instruction don't necessarily have to wait for the instruction to finish. Sometimes they only need part of the results, which are available earlier. So this function will iterate over all children and check if the execution is advanced enough and if so ``release the dependency''. Finally we have to clear the execution list as we will fill it again in the next cycle.

\section{Performing a cycle}

Lastly we want to briefly discuss how a whole cycle is performed. \suaca\ will run each of the three simulation algorithms we explained above. It will then free up all ports, that were used during the cycle, in order to enable the port pipelining. A short pseudo code representation can be found below.

\begin{algorithm}[H]
    \SetAlgoLined
    \caption{Perform a whole cycle}
    load\_instructions()\;
    choose\_ports()\;
    execute\_instructions()\;
    \ForEach{p $\in$ Ports} {
        p.clear()\;
    }
\end{algorithm}

The interesting observation here is that an instruction can actually get loaded, put into a port and then executed within a single cycle, due to the order of the function calls.


\section{The divider pipe}
\label{sec:dividerpipe}
