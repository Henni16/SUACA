In this chapter we are going to compare \suaca\ to both \iaca\ and \osaca. We will evaluate the results and differences of the tools and show how a detailed analysis can be done with \suaca.

\section{Bottleneck Analysis}

Consider the following example run of \iaca\ $2.3$ on the Sandy Bridge architecture:

\begin{example}
        Throughput Analysis Report
        --------------------------
        Block Throughput: 2.00 Cycles       Throughput Bottleneck: FrontEnd
        
        Port Binding In Cycles Per Iteration:
        -------------------------------------------------------------------------
        |  Port  |  0   -  DV  |  1   |  2   -  D   |  3   -  D   |  4   |  5   |
        -------------------------------------------------------------------------
        | Cycles | 2.0    0.0  | 2.0  | 0.0    0.0  | 0.0    0.0  | 0.0  | 2.0  |
        -------------------------------------------------------------------------
        
        N - port number or number of cycles resource conflict caused delay, DV - Divider pipe (on port 0)
        D - Data fetch pipe (on ports 2 and 3), CP - on a critical path
        F - Macro Fusion with the previous instruction occurred
        * - instruction micro-ops not bound to a port
        ^ - Micro Fusion happened
        # - ESP Tracking sync uop was issued
        @ - SSE instruction followed an AVX256/AVX512 instruction, dozens of cycles penalty is expected
        X - instruction not supported, was not accounted in Analysis
        
        | Num Of |              Ports pressure in cycles               |    |
        |  Uops  |  0  - DV  |  1  |  2  -  D  |  3  -  D  |  4  |  5  |    |
        ---------------------------------------------------------------------
        |   1    | 1.0       |     |           |           |     |     | CP | mov rax, 0x6
        |   1    |           | 1.0 |           |           |     |     | CP | mov rax, 0x6
        |   1    |           |     |           |           |     | 1.0 | CP | mov rax, 0x6
        |   1    | 1.0       |     |           |           |     |     | CP | mov rax, 0x6
        |   1    |           | 1.0 |           |           |     |     | CP | mov rax, 0x6
        |   1    |           |     |           |           |     | 1.0 | CP | mov rax, 0x6
        Total Num Of Uops: 6
\end{example}

Note that we constructed this program exclusively for our purposes. Apart from the very first instruction the program will not have any effect. This is fine as it is designed as a toy example.\\
We can observe that the \emph{mov} instruction is able to use ports $0$, $1$ and $5$. The front-end of the Sandy Bridge architecture can deliver up to four \microops\ per cycle and there are no dependencies as no register is ever read.\\
So the clear bottleneck of this program are the three ports, because four \microops\ get loaded but only three ports are available for their execution. Unfortunately we do not know how the bottleneck analysis of \iaca\ works so we cannot argue why it believes that the front-end might be the bottleneck. Looking at the information we do have it does not make sense, though.\\


Now consider \suaca's output of the same program with $200$ iterations:

\begin{example}
Block throughput: 2.00 cycles
Block throughput with perfect front-end: 2.00 cycles
Block throughput with infinitely usable ports: 1.50 cycles
Block throughput without dependencies: 2.00 cycles
Microops per cycle: 3.00
       
Analysis for architecture: SNB
        
 Line  ||   Num   ||   had   || caused  ||            Used Ports
       ||   Uops  || to wait || to wait ||   0   ||   1   ||   2   ||   3   ||   4   ||   5   ||
 ------------------------------------------------------------------------------------------------
   0   ||    1    ||  15.6   ||  46.7   ||  1.0  ||       ||       ||       ||       ||       || mov rax, 0x6
   1   ||    1    ||  15.6   ||  46.7   ||       ||  1.0  ||       ||       ||       ||       || mov rax, 0x6
   2   ||    1    ||  15.5   ||  46.7   ||       ||       ||       ||       ||       ||  1.0  || mov rax, 0x6
   3   ||    1    ||  15.6   ||  46.7   ||  1.0  ||       ||       ||       ||       ||       || mov rax, 0x6
   4   ||    1    ||  15.6   ||  46.7   ||       ||  1.0  ||       ||       ||       ||       || mov rax, 0x6
   5   ||    1    ||  15.6   ||  46.7   ||       ||       ||       ||       ||       ||  1.0  || mov rax, 0x6
Total number of Uops: 6
\end{example}

One can easily see that the port information and the block throughput is identical to \iaca's output. The major difference lies in the bottleneck analysis. \suaca\ tells you that the throughput improves quite drastically with infinitely usable ports. The two cycles make sense with the ports in consideration as we have three usable ports and six instructions, but when each port can be used to an infinite amount each cycle this is no longer relevant. Without the port problem we only need one and a half cycle for each iteration as we have six \microops\ and a front-end that produces four of them each cycle.\\
We can also tell \suaca\ to analyze a specific line for us:

\begin{example}
Detailed delay information for instruction: mov rax, 0x6 in line 0
    
            Maximum latency: 1
            
            Latencies for dependencies:
            This instruction doesn't have any dependencies!
                      
            Delay caused by blocked ports:
             Port || was delayed || has delayed
             ----------------------------------
              0   ||    46.7     ||    15.6
              1   ||     0.0     ||    15.6
              5   ||     0.0     ||    15.6
\end{example}

This detailed analysis shows that each line suffered a delay of $15.6$ cycles from each of its usable ports. This value is equal for all ports, because this instruction only consists of a single \microop\ and is therefore only delayed if all three ports are blocked (see \hyperref[alg:assign]{algorithm~\ref*{alg:assign}}), which will then all be held responsible. As this program does not contain any dependencies, this is also why the delay suffered from the ports equals the \emph{had to wait} value of the original output. Additionally each instruction causes a delay on the port it used.\\
The \emph{caused to wait} value in the original output is thrice as high as the \emph{had to wait} value. This is due to the fact that there are always three instructions that are responsible for a single other instruction's delay.\\

Unfortunately, \osaca\ does not offer a bottleneck analysis which makes this comparison obsolete.


\section{Complete Analysis}

Now we are going to analyze the example provided by the \osaca\ thesis \cite{osaca-thesis}. First consider the underlaying \emph{C} code which represents a 2D-5pt stencil:


\begin{mdframed}[backgroundcolor=light-gray, roundcorner=10pt,leftmargin=1, rightmargin=1, innerleftmargin=15, innertopmargin=1,innerbottommargin=1, outerlinewidth=1, linecolor=light-gray]
    \begin{lstlisting}[language=C, basicstyle=\scriptsize]
for(j = 1; j < M-1; ++j){
    #pragma vector aligned
    for(int i = 1; i < N-1; ++i){
        (*@\textcolor{Green}{IACA\_START}  @*)
        b[j][i] = (a[j][i-1] + a[j][i+1] + a[j-1][i] + a[j+1][i]) * s;
    }
    (*@\textcolor{Green}{IACA\_END}  @*)
}
    \end{lstlisting}
\end{mdframed}

In the following we will analyze the resulting machine code and compare the results of \iaca, \osaca\ and \suaca. We will do so with the Ivy Bridge microarchitecture in mind. First consider \osaca's analysis in \autoref{ex:osaca}. We can observe a different approach to the port bindings here. \osaca\ always tries to distribute the port pressure evenly across all ports to an extent where it does not take previous instructions into account. This basically means that every instruction will always have the same port bindings no matter how the rest of the program looks like. The idea is to give the user more information about possible bindings which are hard to observe when using \iaca. However, this leads to an overestimation of the throughput as the pressure on port $1$ is much higher than it needs to be. The \emph{incq} and \emph{cmpq} instructions do not need to use port $1$ at all as they could instead use port $0$ and even more so the very underused port $5$. 


\begin{LabeledExample}{\osaca\ run}{\label{ex:osaca}}
    Throughput Analysis Report
    --------------------------
    X - No information for this instruction in data file
    " - Instruction micro-ops not bound to a port
    
    Port Binding in Cycles Per Iteration:
    -------------------------------------------------
    | Port   |   0  |   1  |  2  |  3  |  4  |   5  |
    -------------------------------------------------
    | Cycles | 1.67 | 3.67 | 2.5 | 2.5 | 1.0 | 0.67 |
    -------------------------------------------------
    
    Ports Pressure in cycles
    |   0  |   1  |   2  |   3  |   4  |   5  |
    -------------------------------------------
    |      |      | 0.50 | 0.50 |      |      | vmovsd  (%r14,%r15,8), %xmm2
    |      | 1.00 | 0.50 | 0.50 |      |      | vaddsd  16(%r14,%r15,8), %xmm2, %xmm3
    |      | 1.00 | 0.50 | 0.50 |      |      | vaddsd  8(%rax,%r15,8), %xmm3, %xmm4
    |      | 1.00 | 0.50 | 0.50 |      |      | vaddsd  8(%rdx,%r15,8), %xmm4, %xmm5
    | 1.00 |      |      |      |      |      | vmulsd  %xmm5, %xmm1, %xmm6
    |      |      | 0.50 | 0.50 | 1.00 |      | vmovsd  %xmm6, 8(%r12,%r15,8)
    | 0.33 | 0.33 |      |      |      | 0.33 | incq    %r15
    | 0.33 | 0.33 |      |      |      | 0.33 | cmpq    %r13, %r15
    |      |      |      |      |      |      | jb      ..B1.17
    Total number of estimated throughput: 4.67
\end{LabeledExample}

The \osaca\ thesis states,that we can conclude that port $1$ is the bottleneck of this program, which makes sense looking at the given analysis. We will now look into the program a bit further.\\
\autoref{ex:iaca} displays the output of \iaca\ $2.3$ which shows the expected behavior regarding the overused port $1$ i.e., the \emph{incq} and \emph{cmpq} instructions exclusively use port $5$.

\begin{LabeledExample}{\iaca\ run}{\label{ex:iaca}}
  Throughput Analysis Report
  --------------------------
  Block Throughput: 3.00 Cycles       Throughput Bottleneck: FrontEnd
  
  Port Binding In Cycles Per Iteration:
  -------------------------------------------------------------------------
  |  Port  |  0   -  DV  |  1   |  2   -  D   |  3   -  D   |  4   |  5   |
  -------------------------------------------------------------------------
  | Cycles | 1.0    0.0  | 3.0  | 2.5    2.0  | 2.5    2.0  | 1.0  | 2.0  |
  -------------------------------------------------------------------------
  
      
  | Num Of |              Ports pressure in cycles               |    |
  |  Uops  |  0  - DV  |  1  |  2  -  D  |  3  -  D  |  4  |  5  |    |
  ---------------------------------------------------------------------
  |   1    |           |     | 1.0   1.0 |           |     |     |    | vmovsd xmm2, qword ptr [r14+r15*8]
  |   2    |           | 1.0 |           | 1.0   1.0 |     |     | CP | vaddsd xmm3, xmm2, qword ptr [r14+r15*8+0x10]
  |   2    |           | 1.0 | 1.0   1.0 |           |     |     | CP | vaddsd xmm4, xmm3, qword ptr [rax+r15*8+0x8]
  |   2    |           | 1.0 |           | 1.0   1.0 |     |     | CP | vaddsd xmm5, xmm4, qword ptr [rdx+r15*8+0x8]
  |   1    | 1.0       |     |           |           |     |     |    | vmulsd xmm6, xmm1, xmm5
  |   2    |           |     | 0.5       | 0.5       | 1.0 |     |    | vmovsd qword ptr [r12+r15*8+0x8], xmm6
  |   1    |           |     |           |           |     | 1.0 |    | inc r15
  |   1    |           |     |           |           |     | 1.0 |    | cmp r15, r13
  Total Num Of Uops: 12
\end{LabeledExample}

Two properties of this analysis remain unclear. On the one hand, we do not know why those two instructions do not use port $0$ as well. It is a possible port for both of those and it is clearly pressured less. On the other hand the distribution of ports $2$ and $3$ are very strict for the first four instructions and are split for the \nth{6}. \iaca\ may have some internal information that would explain this behavior, but as far as we know this seems odd.\\

\iaca\ declares the front-end as the bottleneck. The front-end of the Ivy Bridge architecture delivers up to four \microops\ per cycle. The example program contains $12$ \microops\ and the throughput is exactly three cycles. So the throughput is certainly lower bounded by the front-end. However, port $1$ is still pressured for three cycles. So even if the front-end was faster the throughput would not improve as it is also lower bounded by the three \emph{vaddsd} instructions that have to use port $1$.\\
This analysis does not show the dependencies at all. If we take a closer look at the first six instructions we can see that those have a dependency chain over the \emph{xmm} registers. We will now consider \suaca's analysis in order to take a closer look at the interactions between front-end, ports and dependencies of our program. We shortened the instructions in the output for the sake of readability.

\begin{LabeledExample}{\suaca\ run - $3000$ iterations}{\label{ex:suaca3000}}
    Block throughput: 3.00 cycles
    Block throughput with perfect front-end: 3.00 cycles
    Block throughput with infinitely usable ports: 3.00 cycles
    Block throughput without dependencies: 3.00 cycles
    Microops per cycle: 3.99
    
    Analysis for architecture: IVB
    
     Line  ||   Num   ||   had   || caused  ||            Used Ports
           ||   Uops  || to wait || to wait ||   0   ||   1   ||   2   ||   3   ||   4   ||   5   ||
     ------------------------------------------------------------------------------------------------
       0   ||    1    ||   0.3   ||   1.3   ||       ||       ||  0.5  ||  0.5  ||       ||       || vmovsd xmm2, ...
       1   ||    2    ||   2.0   ||   5.0   ||       ||  1.0  ||  0.5  ||  0.5  ||       ||       || vaddsd xmm3, ...
       2   ||    2    ||   5.0   ||   7.7   ||       ||  1.0  ||  0.5  ||  0.5  ||       ||       || vaddsd xmm4, ...
       3   ||    2    ||   7.0   ||  10.3   ||       ||  1.0  ||  0.5  ||  0.5  ||       ||       || vaddsd xmm5, ...
       4   ||    1    ||  10.0   ||  14.0   ||  1.0  ||       ||       ||       ||       ||       || vmulsd xmm6, ...
       5   ||    2    ||  14.0   ||   0.3   ||       ||       ||  0.5  ||  0.5  ||  1.0  ||       || vmovsd qword ...
       6   ||    1    ||         ||   1.0   ||  0.2  ||       ||       ||       ||       ||  0.8  || inc r15
       7   ||    1    ||   1.0   ||         ||  0.3  ||       ||       ||       ||       ||  0.7  || cmp r15, r13
    Total number of Uops: 12
\end{LabeledExample}  

For the most part this looks pretty similar to the other two analyses. We can observe that the \emph{incq} and \emph{cmpq} instructions are now distributed over ports $0$ and $5$ in a way that both of those ports experience an equal pressure and that ports $2$ and $3$ are evenly used just like in \autoref{ex:osaca}.\\
The throughput is equal to \iaca's output and the throughput values of the special analyses do not differ, because of the properties we explained above. We will now use \suaca's runtime options to gain a better picture of the program's problems. First consider the run with only a single iteration in \autoref{ex:suacasingle}. We can see that the throughput (which would also be the latency in this particular case) is drastically higher and more important, that the dependencies are the biggest offender. This is due to the long dependency chain from the first to the sixth instruction. So in a single iteration of this program almost every instruction has to wait for its predecessor to be finished.

\begin{LabeledExample}{\suaca\ run - single iteration}{\label{ex:suacasingle}}
    Block throughput: 16.00 cycles
    Block throughput with perfect front-end: 16.00 cycles
    Block throughput with infinitely usable ports: 16.00 cycles
    Block throughput without dependencies: 6.00 cycles
    Microops per cycle: 0.75
    
    Analysis for architecture: IVB
    
     Line  ||   Num   ||   had   || caused  ||            Used Ports
           ||   Uops  || to wait || to wait ||   0   ||   1   ||   2   ||   3   ||   4   ||   5   ||
     ------------------------------------------------------------------------------------------------
       0   ||    1    ||         ||   1.0   ||       ||       ||  1.0  ||       ||       ||       || vmovsd xmm2, ...
       1   ||    2    ||   1.0   ||   4.0   ||       ||  1.0  ||       ||  1.0  ||       ||       || vaddsd xmm3, ...
       2   ||    2    ||   4.0   ||   6.0   ||       ||  1.0  ||  1.0  ||       ||       ||       || vaddsd xmm4, ...
       3   ||    2    ||   6.0   ||   9.0   ||       ||  1.0  ||       ||  1.0  ||       ||       || vaddsd xmm5, ...
       4   ||    1    ||   9.0   ||  13.0   ||  1.0  ||       ||       ||       ||       ||       || vmulsd xmm6, ...
       5   ||    2    ||  13.0   ||         ||       ||       ||  1.0  ||       ||  1.0  ||       || vmovsd qword ...
       6   ||    1    ||         ||   1.0   ||  1.0  ||       ||       ||       ||       ||       || inc r15
       7   ||    1    ||   1.0   ||         ||       ||       ||       ||       ||       ||  1.0  || cmp r15, r13
    Total number of Uops: 12
\end{LabeledExample}

However, there is only a single dependency between consecutive iterations. The \emph{inc} instructions writes to \emph{r15} which will be read by the following iteration multiple times, so we can simply interpret this as the start of our ``single iteration dependency chain''. Those chains make sense as the program is iterating over an array.\\
When this program runs in a loop the different iterations will run ``side by side'', which explains why the throughput ultimately reaches a value that is lower bounded by the front-end and port $1$. This is also the reason why we chose to run \autoref{ex:suaca3000} with $3000$ iterations as it takes a while until the average ultimately reaches this lower bound.\\
Now that we know which role the dependencies play in our program we can take a closer look at the front-end and the ports. In \autoref{ex:suaca200} one can see the analysis with $200$ iterations which has several interesting results in comparison to \autoref{ex:suaca3000}.


\begin{LabeledExample}{\suaca\ run - $200$ iterations}{\label{ex:suaca200}}
    Block throughput: 3.07 cycles
    Block throughput with perfect front-end: 3.06 cycles
    Block throughput with infinitely usable ports: 3.06 cycles
    Block throughput without dependencies: 3.02 cycles
    Microops per cycle: 3.91
    
    Analysis for architecture: IVB
    
     Line  ||   Num   ||   had   || caused  ||            Used Ports
           ||   Uops  || to wait || to wait ||   0   ||   1   ||   2   ||   3   ||   4   ||   5   ||
     ------------------------------------------------------------------------------------------------
       0   ||    1    ||   0.3   ||   1.3   ||       ||       ||  0.5  ||  0.5  ||       ||       || vmovsd xmm2, ...
       1   ||    2    ||   2.0   ||   5.0   ||       ||  1.0  ||  0.5  ||  0.5  ||       ||       || vaddsd xmm3, ...
       2   ||    2    ||   5.0   ||   7.7   ||       ||  1.0  ||  0.5  ||  0.5  ||       ||       || vaddsd xmm4, ...
       3   ||    2    ||   7.0   ||  10.3   ||       ||  1.0  ||  0.5  ||  0.5  ||       ||       || vaddsd xmm5, ...
       4   ||    1    ||  10.0   ||  14.0   ||  1.0  ||       ||       ||       ||       ||       || vmulsd xmm6, ...
       5   ||    2    ||  14.0   ||   0.3   ||       ||       ||  0.5  ||  0.5  ||  1.0  ||       || vmovsd qword ...
       6   ||    1    ||         ||   1.0   ||  0.2  ||       ||       ||       ||       ||  0.8  || inc r15
       7   ||    1    ||   1.0   ||         ||  0.3  ||       ||       ||       ||       ||  0.7  || cmp r15, r13
    Total number of Uops: 12
\end{LabeledExample}

We can observe that the throughput values have not reached the $3.00$ mark yet, like we discussed above. But more importantly the \emph{had to wait} and \emph{caused to wait} values did not change at all. Usually those increase when the number of iterations is increased. This is the case when the front-end works faster than the execution, because our simulation will only count those values for the instructions that have been loaded into the scheduler already. So if a lot of instructions are waiting inside the scheduler the \emph{had to wait} and \emph{caused to wait} values will be very high. As this is clearly not the case here we can conclude that (after a few iterations) the scheduler is always filled to an equal amount. This actually supports \iaca's claim that the front-end is the bottleneck. We argued that, should the front-end's performance improve, the ports will prevent a faster execution.\\
In \autoref{ex:pf} we can see a run of the perfect front-end analysis. We used $3000$ iterations for this and all the following example runs. The only difference are the two delay values which are a bit higher.


\begin{LabeledExample}{\suaca\ run - perfect front-end}{\label{ex:pf}}
    Block throughput: 3.00 cycles
    Microops per cycle: 4.00
    
    Analysis for architecture: IVB
    
     Line  ||   Num   ||   had   || caused  ||            Used Ports
           ||   Uops  || to wait || to wait ||   0   ||   1   ||   2   ||   3   ||   4   ||   5   ||
     ------------------------------------------------------------------------------------------------
       0   ||    1    ||   1.3   ||   1.7   ||       ||       ||  0.5  ||  0.5  ||       ||       || vmovsd xmm2, ...
       1   ||    2    ||  12.0   ||  18.3   ||       ||  1.0  ||  0.5  ||  0.5  ||       ||       || vaddsd xmm3, ...
       2   ||    2    ||  15.0   ||  20.3   ||       ||  1.0  ||  0.5  ||  0.5  ||       ||       || vaddsd xmm4, ...
       3   ||    2    ||  17.0   ||  24.6   ||       ||  1.0  ||  0.5  ||  0.5  ||       ||       || vaddsd xmm5, ...
       4   ||    1    ||  20.0   ||  24.7   ||  1.0  ||       ||       ||       ||       ||       || vmulsd xmm6, ...
       5   ||    2    ||  24.7   ||   1.3   ||       ||       ||  0.5  ||  0.5  ||  1.0  ||       || vmovsd qword ...
       6   ||    1    ||   0.0   ||   1.7   ||  0.2  ||       ||       ||       ||       ||  0.8  || inc r15
       7   ||    1    ||   1.0   ||         ||  0.3  ||       ||       ||       ||       ||  0.7  || cmp r15, r13
    Total number of Uops: 12
\end{LabeledExample}


The details of line three (\autoref{ex:detail}) show that this is actually due to dependencies for the most part.

\begin{LabeledExample}{Details of line $3$ with perfect front-end}{\label{ex:detail}}
                                        Maximum latency: 3
                                        
                                        Latencies for dependencies:
                                         Line || 3 -> Line || Line -> 3
                                        ----------------------------------
                                          2   ||     0     ||     3
                                          4   ||     3     ||     0
                                          6   ||     0     ||     1
                                        
                                        
                                        Delay caused by dependencies:
                                         Line || was delayed || has delayed
                                        ----------------------------------
                                          2   ||     0.0     ||    17.0
                                          4   ||    20.0     ||     0.0
                                          6   ||     0.0     ||     0.0
                                        
                                        
                                        Delay caused by blocked ports:
                                         Port || was delayed || has delayed
                                        ----------------------------------
                                          1   ||     4.0     ||     0.0
                                          2   ||     0.3     ||     0.0
                                          3   ||     0.3     ||     0.0
\end{LabeledExample}

In order to prove our port claim we will run \suaca\ with both a perfect front-end and disabled dependencies in \autoref{ex:portsonly}. We can exactly observe the above described behavior. The throughput does not improve and the three \emph{vaddsd} instructions are heavily delayed by port $1$, whereas all the other instructions experience very little to no delay. The reason why those delay values are so small is the massive delay of the \emph{vaddsd} instructions as those will continue to be executed for so many cycles that the average delay values of the other instructions are neglected almost completely.


\begin{LabeledExample}{\suaca\ run with pf and nd}{\label{ex:portsonly}}
    Block throughput: 3.00 cycles
    Microops per cycle: 4.00
    
    Analysis for architecture: IVB
    
     Line  ||   Num   ||   had   || caused  ||            Used Ports
           ||   Uops  || to wait || to wait ||   0   ||   1   ||   2   ||   3   ||   4   ||   5   ||
     ------------------------------------------------------------------------------------------------
       0   ||    1    ||   0.2   ||   1.5   ||       ||       ||  0.5  ||  0.5  ||       ||       || vmovsd xmm2, ...
       1   ||    2    ||  48.4   ||  50.9   ||       ||  1.0  ||  0.5  ||  0.5  ||       ||       || vaddsd xmm3, ...
       2   ||    2    ||  49.4   ||  48.9   ||       ||  1.0  ||  0.5  ||  0.5  ||       ||       || vaddsd xmm4, ...
       3   ||    2    ||  49.4   ||  49.9   ||       ||  1.0  ||  0.5  ||  0.5  ||       ||       || vaddsd xmm5, ...
       4   ||    1    ||   0.0   ||   0.0   ||  1.0  ||       ||       ||       ||       ||       || vmulsd xmm6, ...
       5   ||    2    ||   0.3   ||   0.5   ||       ||       ||  0.5  ||  0.5  ||  1.0  ||       || vmovsd qword ...
       6   ||    1    ||   0.0   ||   0.0   ||       ||       ||       ||       ||       ||  1.0  || inc r15
       7   ||    1    ||   0.0   ||   0.0   ||  1.0  ||       ||       ||       ||       ||  0.0  || cmp r15, r13
    Total number of Uops: 12
\end{LabeledExample}

Finally \autoref{ex:deponly} shows what happens when only the dependencies are taken into consideration and it displays a much higher throughput that is probably only bounded by the capacity of the scheduler ($54$ \microops\ in Ivy Bridge). As discussed above the program basically has no loop dependencies which leads to the results we are seeing.

\begin{LabeledExample}{\suaca\ run with pf and ip}{\label{ex:deponly}}
    Block throughput: 1.50 cycles
    Microops per cycle: 7.98
    
    Analysis for architecture: IVB
    
     Line  ||   Num   ||   had   || caused  ||            Used Ports
           ||   Uops  || to wait || to wait ||   0   ||   1   ||   2   ||   3   ||   4   ||   5   ||
     ------------------------------------------------------------------------------------------------
       0   ||    1    ||   1.0   ||   2.0   ||       ||       ||  0.5  ||  0.5  ||       ||       || vmovsd xmm2, ...
       1   ||    2    ||   2.0   ||   4.5   ||       ||  1.0  ||  0.0  ||  1.0  ||       ||       || vaddsd xmm3, ...
       2   ||    2    ||   4.5   ||   7.5   ||       ||  1.0  ||  1.0  ||  0.0  ||       ||       || vaddsd xmm4, ...
       3   ||    2    ||   7.5   ||  10.0   ||       ||  1.0  ||  0.0  ||  1.0  ||       ||       || vaddsd xmm5, ...
       4   ||    1    ||  10.0   ||  14.5   ||  1.0  ||       ||       ||       ||       ||       || vmulsd xmm6, ...
       5   ||    2    ||  14.5   ||         ||       ||       ||  1.0  ||  0.0  ||  1.0  ||       || vmovsd qword ...
       6   ||    1    ||   0.0   ||   4.0   ||  0.5  ||       ||       ||       ||       ||  0.5  || inc r15
       7   ||    1    ||   1.0   ||         ||       ||       ||       ||       ||       ||  1.0  || cmp r15, r13
    Total number of Uops: 12
\end{LabeledExample}


All in all we can conclude that this program is very tricky and takes some serious thought to fully understand its issues. \suaca\ delivers various tools to gain insight into it and using \suaca\ we were able to get a good idea of the program's performance.


\section{Flag Dependencies}

For our final example we will use \iaca\ $3.0$ and consider the following code snippet:

\begin{mdframed}[backgroundcolor=light-gray, roundcorner=10pt,leftmargin=1, rightmargin=1, innerleftmargin=15, innertopmargin=1,innerbottommargin=1, outerlinewidth=1, linecolor=light-gray]
    \begin{lstlisting}[language={myLang}, basicstyle=\small, numbers=left]
    adc rax, 0x1
    adc rbx, 0x1
    adc rcx, 0x1
    adc rdx, 0x1
    adc r8,  0x1
    adc r9,  0x1
    adc r10, 0x1
    adc r11, 0x1
    \end{lstlisting}
\end{mdframed}

\FloatBarrier

At first this program seems to be free of dependencies. However, the \emph{adc} instruction is the ``add with carry'' instruction which reads and writes to the \emph{cf} bit (carry flag) of the \emph{RFLAGS} register. So there actually is a huge dependency loop that prevents any parallel execution as well as instruction reordering. \autoref{fig:cfg2} shows \suaca's dependency graph for this program, which of course also includes a self loop for every instruction.\\
Unfortunately, we do not know which dependencies \iaca\ $3.0$ uses exactly for its computations, but as it computes a throughput of $3.95$ cycles we can conclude that it definitely does not know about the \emph{cf} bit. This also leads to the back-end being held responsible for being the bottleneck. The full output can be seen in \autoref{ex:3.0}. We used the Skylake microarchitecture for this example. 

\begin{LabeledExample}{\iaca\ $3.0$'s output}{\label{ex:3.0}}
    Throughput Analysis Report
    --------------------------
    Block Throughput: 3.95 Cycles       Throughput Bottleneck: Backend
    Loop Count:  22
    Port Binding In Cycles Per Iteration:
    --------------------------------------------------------------------------------------------------
    |  Port  |   0   -  DV   |   1   |   2   -  D    |   3   -  D    |   4   |   5   |   6   |   7   |
    --------------------------------------------------------------------------------------------------
    | Cycles |  4.0     0.0  |  0.0  |  0.0     0.0  |  0.0     0.0  |  0.0  |  0.0  |  4.0  |  0.0  |
    --------------------------------------------------------------------------------------------------
    
    
    | Num Of   |                    Ports pressure in cycles                         |      |
    |  Uops    |  0  - DV    |  1   |  2  -  D    |  3  -  D    |  4   |  5   |  6   |  7   |
    -----------------------------------------------------------------------------------------
    |   1      | 1.0         |      |             |             |      |      |      |      | adc rax, 0x1
    |   1      |             |      |             |             |      |      | 1.0  |      | adc rbx, 0x1
    |   1      | 1.0         |      |             |             |      |      |      |      | adc rcx, 0x1
    |   1      |             |      |             |             |      |      | 1.0  |      | adc rdx, 0x1
    |   1      | 1.0         |      |             |             |      |      |      |      | adc r8, 0x1
    |   1      |             |      |             |             |      |      | 1.0  |      | adc r9, 0x1
    |   1      | 1.0         |      |             |             |      |      |      |      | adc r10, 0x1
    |   1      |             |      |             |             |      |      | 1.0  |      | adc r11, 0x1
    Total Num Of Uops: 8
    Analysis Notes:
    Backend allocation was stalled due to unavailable allocation resources.
\end{LabeledExample}

\setlength{\abovecaptionskip}{-30pt}
\begin{figure}[H]
    \centering
    \resizebox{!}{\textheight}{
        \begin{tikzpicture}
        \node[mynode] (A) at (0, 0)     {0: adc rax, 0x1};	
        \node[mynode] (B) at (0, -2.5)    {1: adc rbx, 0x1};
        \node[mynode] (C) at (0, -5)    {2: adc rcx, 0x1};
        \node[mynode] (D) at (0, -7.5)    {3: adc rdx, 0x1};
        \node[mynode] (E) at (0, -10)    {4: adc r8,  0x1};
        \node[mynode] (F) at (0, -12.5)   {5: adc r9, 0x1};
        \node[mynode] (G) at (0, -15)   {6: adc r10, 0x1};
        \node[mynode] (H) at (0, -17.5)   {7: adc r11, 0x1};
        
        \Loop[style={->, dashed, thick}, color=red, label=$RAX$, labelstyle={color=red,fill=white,draw}](A.west);
        \Loop[style={->, dashed, thick}, color=red, label=$RBX$, labelstyle={color=red,fill=white,draw}](B.west);
        \Loop[style={->, dashed, thick}, color=red, label=$RCX$, labelstyle={color=red,fill=white,draw}](C.west);
        \Loop[style={->, dashed, thick}, color=red, label=$RDX$, labelstyle={color=red,fill=white,draw}](D.west);
        \Loop[style={->, dashed, thick}, color=red, label=$R8$, labelstyle={color=red,fill=white,draw}](E.west);
        \Loop[style={->, dashed, thick}, color=red, label=$R9$, labelstyle={color=red,fill=white,draw}](F.west);
        \Loop[style={->, dashed, thick}, color=red, label=$R10$, labelstyle={color=red,fill=white,draw}](G.west);
        \Loop[style={->, dashed, thick}, color=red, label=$R11$, labelstyle={color=red,fill=white,draw}](H.west);
        \Edges[label=$RFLAGS - cf$](A,B);
        \Edges[label=$RFLAGS - cf$](B,C);
        \Edges[label=$RFLAGS - cf$](C,D);
        \Edges[label=$RFLAGS - cf$](D,E);
        \Edges[label=$RFLAGS - cf$](E,F);
        \Edges[label=$RFLAGS - cf$](F,G);
        \Edges[label=$RFLAGS - cf$](G,H);
        \Edges[style={->, bend right = 90, dashed}, color=red, label=$RFLAGS - cf$](H,A);
        
        \end{tikzpicture}}
    \caption{Dependency graph}
    \label{fig:cfg2}
\end{figure}


As one can see in \autoref{ex:3.0suaca} \suaca's results are identical for the port pressure, but as it does include the dependency loop it computes a throughput of $8.0$ cycles. The throughput without dependencies is measured with $4.0$ cycles which makes sense the example contains $8$ \microops\ and two usable ports. We have again cut the first two columns for the sake of readability.

\begin{LabeledExample}{\suaca's output for SKL with $200$ iterations}{\label{ex:3.0suaca}}
    Block throughput: 8.00 cycles
    Block throughput with perfect front-end: 8.00 cycles
    Block throughput with infinitely usable ports: 8.00 cycles
    Block throughput without dependencies: 4.00 cycles
    Microops per cycle: 1.00
    
    Analysis for architecture: SKL
    
        had   || caused  ||            Used Ports
      to wait || to wait ||   0   ||   1   ||   2   ||   3   ||   4   ||   5   ||   6   ||   7   ||
     ------------------------------------------------------------------------------------------------------------
       92.2   || 177.5   ||  1.0  ||       ||       ||       ||       ||       ||       ||       || adc rax, 0x1
       92.3   || 177.6   ||       ||       ||       ||       ||       ||       ||  1.0  ||       || adc rbx, 0x1
       92.3   || 177.7   ||  1.0  ||       ||       ||       ||       ||       ||       ||       || adc rcx, 0x1
       92.4   || 177.8   ||       ||       ||       ||       ||       ||       ||  1.0  ||       || adc rdx, 0x1
       92.4   || 177.9   ||  1.0  ||       ||       ||       ||       ||       ||       ||       || adc r8, 0x1
       92.5   || 178.1   ||       ||       ||       ||       ||       ||       ||  1.0  ||       || adc r9, 0x1
       92.5   || 178.2   ||  1.0  ||       ||       ||       ||       ||       ||       ||       || adc r10, 0x1
       92.6   || 177.8   ||       ||       ||       ||       ||       ||       ||  1.0  ||       || adc r11, 0x1
    Total number of Uops: 8
\end{LabeledExample}

This seems to be a problem introduced in \iaca\ $3.0$ as \iaca\ $2.3$ computes a throughput of $7.62$ cycles and declares the dependency chains as the bottleneck.
